{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Tensor Basics\n",
    "This notebook explains different kinds of tensors in PyTorch — scalars, vectors, matrices, and higher-dimensional tensors — along with basic operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalar\n",
    "A scalar is a single number (0-dimensional tensor).\n",
    "1. Structure.ndim - gives the number of dimension the structure have.\n",
    "2. Structure.item - converts the type of the structure back to the python int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n",
      "0\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "scalar=torch.tensor(7)\n",
    "print(scalar)\n",
    "print(scalar.ndim) #no. of dimention does scalar have\n",
    "print(scalar.item()) #Get tensor back as python int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector (1D tensor)\n",
    "1. Structure.shape - gives the structure size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 9])\n",
      "1\n",
      "tensor(9)\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "vector=torch.tensor([6,9])\n",
    "print(vector)\n",
    "print(vector.ndim)\n",
    "print(vector[1])\n",
    "print(vector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix (2D tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7,  8],\n",
      "        [ 9, 10]])\n",
      "2\n",
      "tensor([ 9, 10])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "matrix=torch.tensor([[7,8],\n",
    "                     [9,10]])\n",
    "print(matrix)\n",
    "print(matrix.ndim)\n",
    "print(matrix[1])\n",
    "print(matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor (3D example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2,  3],\n",
      "         [ 3,  6,  9],\n",
      "         [10, 11, 12]]])\n",
      "3\n",
      "torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "tensor=torch.tensor([[[1,2,3],\n",
    "                      [3,6,9],\n",
    "                      [10,11,12]]])\n",
    "print(tensor)\n",
    "print(tensor.ndim)\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Tensor\n",
    "Creating a Random Tensor of size --> rows=3 and columns=4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5930, 0.3939, 0.5457, 0.7840],\n",
      "        [0.6240, 0.7044, 0.5064, 0.4923],\n",
      "        [0.5315, 0.9990, 0.4856, 0.7886]])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "random_tensor=torch.rand(size=(3,4))\n",
    "print(random_tensor)\n",
    "print(random_tensor.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random tensor shaped like an image (Height, Width, Channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([224, 224, 3])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "random_image_size_tensor=torch.rand(size=(224,224,3))\n",
    "print(random_image_size_tensor.shape)\n",
    "print(random_image_size_tensor.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zeros and Ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "zeros=torch.zeros(size=(3,4))\n",
    "print(zeros)\n",
    "print(zeros*random_tensor)\n",
    "ones=torch.ones(size=(3,4))\n",
    "print(ones)\n",
    "print(ones.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating ranges of tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n",
      "tensor([  1,  51, 101, 151, 201, 251, 301, 351, 401, 451, 501, 551, 601, 651,\n",
      "        701, 751, 801, 851, 901, 951])\n"
     ]
    }
   ],
   "source": [
    "zero_to_nine=torch.arange(0,10)\n",
    "print(zero_to_nine)\n",
    "one_to_ten=torch.arange(1,11)\n",
    "print(one_to_ten)\n",
    "one_to_thousand_with_50steps=torch.arange(start=1, end=1000, step=50)\n",
    "print(one_to_thousand_with_50steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating tensor-like another tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "one_to_ten=torch.zeros_like(input=one_to_ten)\n",
    "print(one_to_ten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Datatypes and Devices\n",
    "**NOTE:** tensor datatypes is one of the 3 big errors you'll run into with pytorch & deep learning \n",
    "1. tensor not right datatype\n",
    "2. tensor not right shape\n",
    "3. tensor not on the right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 6., 9.])\n",
      "torch.float32\n",
      "tensor([2., 4., 6.], device='cuda:0', dtype=torch.float16)\n",
      "torch.float16\n"
     ]
    }
   ],
   "source": [
    "float32_tensor=torch.tensor([3.0, 6.0, 9.0],\n",
    "                            dtype=None, #what data type is the tensor (default=float32)\n",
    "                            device=None, #what device is your tensor on (default=None=cpu)\n",
    "                            requires_grad=False) #whether or not to track gradiants with this tensor operation\n",
    "print(float32_tensor)\n",
    "print(float32_tensor.dtype)\n",
    "float16_tensor=torch.tensor([2.0, 4.0, 6.0],\n",
    "                            dtype=torch.float16,\n",
    "                            device=\"cuda\",\n",
    "                            requires_grad=False)\n",
    "print(float16_tensor)\n",
    "print(float16_tensor.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 6., 9.], dtype=torch.float16)\n",
      "tensor([ 9., 36., 81.])\n",
      "tensor([2, 3, 4], dtype=torch.int32)\n",
      "tensor([ 6., 18., 36.])\n"
     ]
    }
   ],
   "source": [
    "float16_tensor=float32_tensor.type(torch.float16)\n",
    "print(float16_tensor)\n",
    "print(float16_tensor*float32_tensor)\n",
    "int_32_tensor=torch.tensor([2,3,4], dtype=torch.int32)\n",
    "print(int_32_tensor)\n",
    "print(float32_tensor*int_32_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking tensor attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5666, 0.5803, 0.3077, 0.2764],\n",
      "        [0.8799, 0.7992, 0.7093, 0.5071],\n",
      "        [0.7582, 0.3065, 0.1434, 0.1781]])\n",
      "Datatype of tensor: torch.float32\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Device of tensor: cpu\n"
     ]
    }
   ],
   "source": [
    "some_tensor=torch.rand(3, 4)\n",
    "print(some_tensor)\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Device of tensor: {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic tensor operations (Addition, Subtraction, Multiplication, Division)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11, 12, 13])\n",
      "tensor([-9, -8, -7])\n",
      "tensor([10, 20, 30])\n",
      "tensor([0.1000, 0.2000, 0.3000])\n",
      "tensor([11, 12, 13])\n",
      "tensor([-9, -8, -7])\n",
      "tensor([10, 20, 30])\n",
      "tensor([0.1000, 0.2000, 0.3000])\n"
     ]
    }
   ],
   "source": [
    "tensor=torch.tensor([1,2,3])\n",
    "print(tensor+10)\n",
    "print(tensor-10) #SLOW\n",
    "print(tensor*10)\n",
    "print(tensor/10)\n",
    "#OR\n",
    "print(torch.add(tensor, 10))\n",
    "print(torch.sub(tensor, 10)) #FAST\n",
    "print(torch.mul(tensor, 10))\n",
    "print(torch.div(tensor, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Multiplication\n",
    "**NOTE:** There are 2 types of matrix multiplication:\n",
    "1. Element wise multiplication.\n",
    "2. Matrix multiplication (dot product)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals: tensor([1, 4, 9])\n",
      "tensor(14)\n",
      "tensor(14)\n"
     ]
    }
   ],
   "source": [
    "print(tensor, \"*\", tensor)\n",
    "print(f\"Equals: {tensor*tensor}\")\n",
    "print(torch.matmul(tensor, tensor))\n",
    "#OR\n",
    "print(tensor @ tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34839e54",
   "metadata": {},
   "source": [
    "# 2 Rules\n",
    "There are two main rules that performing matrix multiplication needs to satisfy:\n",
    "### 1. Inner Dimension Should Match.\n",
    "1. torch.Size([3, 2]) @ torch.Size([3, 4]) won't work'.\n",
    "2. torch.Size([3, 2]) @ torch.Size([2, 5]) will work'.\n",
    "3. torch.Size([2, 3]) @ torch.Size([3, 1]) will work'.\n",
    "**NOTE:** In matrix A*B != B*A.\n",
    "### 2. The resulting matrix has the shape of the Outer Dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e295bf77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.4268, 0.7305, 1.3250, 0.9002, 1.2727, 1.6670],\n",
      "        [1.0518, 0.8206, 0.7554, 0.7349, 0.7816, 1.0639]])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "matrixmul=torch.matmul(torch.rand(2,3), torch.rand(3,6))\n",
    "print(matrixmul)\n",
    "print(matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e2e5f1",
   "metadata": {},
   "source": [
    "# Transpose Matrix\n",
    "To Fix our tensor shape issues, we can manipulate the shape of one of our tensors using a TRANSPOSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1696b8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4665, 0.1836, 0.3292],\n",
      "        [0.9140, 0.4906, 0.3933]])\n",
      "tensor([[0.4665, 0.9140],\n",
      "        [0.1836, 0.4906],\n",
      "        [0.3292, 0.3933]])\n",
      "tensor([[0.2887, 0.6602, 0.4189],\n",
      "        [0.3984, 0.7172, 0.4774]])\n",
      "tensor([[0.2887, 0.3984],\n",
      "        [0.6602, 0.7172],\n",
      "        [0.4189, 0.4774]])\n",
      "tensor([[0.4988, 0.9635, 0.6317],\n",
      "        [0.2485, 0.4731, 0.3111],\n",
      "        [0.2517, 0.4994, 0.3257]])\n",
      "tensor([[0.3937, 0.4746],\n",
      "        [0.7525, 0.9038]])\n"
     ]
    }
   ],
   "source": [
    "A=torch.rand(2,3)\n",
    "B=torch.rand(2,3)\n",
    "# print(A @ B) will not work cuz the inner dimension are not same\n",
    "# we have to transpose any one of them\n",
    "print(A)\n",
    "print(A.T)\n",
    "print(B)\n",
    "print(B.T)\n",
    "print(A.T @ B)\n",
    "print(A @ B.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregations (min, max, mean, sum, argmin, argmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 10,  20,  30,  40,  50,  60,  70,  80,  90, 100])\n",
      "Minimum: 10\n",
      "Maximum: 100\n",
      "Mean: 55.0\n",
      "Sum: 550\n"
     ]
    }
   ],
   "source": [
    "tensorA=torch.arange(10, 110, 10)\n",
    "print(tensorA)\n",
    "print(f\"Minimum: {torch.min(tensorA)}\")\n",
    "print(f\"Maximum: {torch.max(tensorA)}\")\n",
    "print(f\"Mean: {torch.mean(tensorA.type(torch.float32))}\")\n",
    "# mean can calculated only for floating numbers\n",
    "print(f\"Sum: {torch.sum(tensorA)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b49eedf",
   "metadata": {},
   "source": [
    "## Positional min, max and mean\n",
    "##### Shows the position of the min or max value in the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d9c95dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "tensor(9)\n",
      "tensor(0)\n",
      "tensor(9)\n",
      "tensor(10)\n",
      "tensor(100)\n"
     ]
    }
   ],
   "source": [
    "print(tensorA.argmin())\n",
    "print(tensorA.argmax())\n",
    "print(torch.argmin(tensorA))\n",
    "print(torch.argmax(tensorA))\n",
    "print(tensorA[0])\n",
    "print(tensorA[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping, Stacking, Squeezing, Unsqueezing, Permuting\n",
    "#### 1) Reshaping - reshapes the input tensor to a defined shape\n",
    "#### 2) View - return a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
    "#### 3) Stacking - combine multiple tensors on top of eachother (vstack) or side by side (hstack)\n",
    "#### 4) Squeezwe - removes all one dimension from a tensor\n",
    "#### 5) Unsqueeze - adds a one dimension to a target tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]) torch.Size([10])\n",
      "tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]]) torch.Size([1, 10])\n",
      "tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]]) torch.Size([1, 10])\n",
      "tensor([[ 5,  2,  3,  4,  5,  6,  7,  8,  9, 10]]) tensor([ 5,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n",
      "tensor([[ 5,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 5,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 5,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 5,  2,  3,  4,  5,  6,  7,  8,  9, 10]])\n",
      "tensor([[ 5,  5,  5,  5],\n",
      "        [ 2,  2,  2,  2],\n",
      "        [ 3,  3,  3,  3],\n",
      "        [ 4,  4,  4,  4],\n",
      "        [ 5,  5,  5,  5],\n",
      "        [ 6,  6,  6,  6],\n",
      "        [ 7,  7,  7,  7],\n",
      "        [ 8,  8,  8,  8],\n",
      "        [ 9,  9,  9,  9],\n",
      "        [10, 10, 10, 10]])\n",
      "Previous tensor and its shape:  tensor([[ 5,  2,  3,  4,  5,  6,  7,  8,  9, 10]]) torch.Size([1, 10])\n",
      "After removing extra dimensions from x_reshape:  tensor([ 5,  2,  3,  4,  5,  6,  7,  8,  9, 10]) torch.Size([10])\n",
      "Previous tensor and its shape:  tensor([ 5,  2,  3,  4,  5,  6,  7,  8,  9, 10]) torch.Size([10])\n",
      "After unsqueezing the squeesed tensor be like:  tensor([[ 5,  2,  3,  4,  5,  6,  7,  8,  9, 10]]) torch.Size([1, 10])\n",
      "After unsqueezing the squeesed tensor be like:  tensor([[ 5],\n",
      "        [ 2],\n",
      "        [ 3],\n",
      "        [ 4],\n",
      "        [ 5],\n",
      "        [ 6],\n",
      "        [ 7],\n",
      "        [ 8],\n",
      "        [ 9],\n",
      "        [10]]) torch.Size([10, 1])\n",
      "tensor([[[0.5869, 0.4843],\n",
      "         [0.4874, 0.6969],\n",
      "         [0.3282, 0.9441],\n",
      "         [0.9618, 0.2844]],\n",
      "\n",
      "        [[0.2713, 0.9090],\n",
      "         [0.5131, 0.8979],\n",
      "         [0.4374, 0.8627],\n",
      "         [0.3806, 0.2292]],\n",
      "\n",
      "        [[0.9552, 0.6419],\n",
      "         [0.4423, 0.2677],\n",
      "         [0.5244, 0.8400],\n",
      "         [0.2705, 0.7649]]]) torch.Size([3, 4, 2])\n",
      "tensor([[[0.5869, 0.4874, 0.3282, 0.9618],\n",
      "         [0.2713, 0.5131, 0.4374, 0.3806],\n",
      "         [0.9552, 0.4423, 0.5244, 0.2705]],\n",
      "\n",
      "        [[0.4843, 0.6969, 0.9441, 0.2844],\n",
      "         [0.9090, 0.8979, 0.8627, 0.2292],\n",
      "         [0.6419, 0.2677, 0.8400, 0.7649]]]) torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "#Reshaping\n",
    "x=torch.arange(1, 11)\n",
    "print(x, x.shape)\n",
    "x_reshaped=x.reshape(1,10) # only works when (1*10 = actual x size)\n",
    "print(x_reshaped, x_reshaped.shape)\n",
    "\n",
    "#Viewing\n",
    "z=x.view(1,10)\n",
    "print(z,z.shape) # changing z changes x(bcuz a view of tensor shares the same memory as the original input)\n",
    "z[:, 0]=5\n",
    "print(z,x)\n",
    "\n",
    "#Stacking\n",
    "x_stacked=torch.stack([x,x,x,x],dim=0) #hstack\n",
    "print(x_stacked)\n",
    "x_stacked=torch.stack([x,x,x,x],dim=1) #vstack\n",
    "print(x_stacked)\n",
    "\n",
    "#Squeezing\n",
    "print(f\"Previous tensor and its shape: \",x_reshaped,x_reshaped.shape)\n",
    "x_squeezed=x_reshaped.squeeze()\n",
    "print(f\"After removing extra dimensions from x_reshape: \",x_squeezed,x_squeezed.shape)\n",
    "\n",
    "#Unsqueeze\n",
    "print(f\"Previous tensor and its shape: \",x_squeezed,x_squeezed.shape)\n",
    "x_unsqueezed=x_squeezed.unsqueeze(dim=0) #need the dimension input to unsqeeze the tenor (adding the dimension)\n",
    "print(f\"After unsqueezing the squeesed tensor be like: \",x_unsqueezed,x_unsqueezed.shape)\n",
    "x_unsqueezed=x_squeezed.unsqueeze(dim=1)\n",
    "print(f\"After unsqueezing the squeesed tensor be like: \",x_unsqueezed,x_unsqueezed.shape)\n",
    "\n",
    "#Permute\n",
    "x_og=torch.rand(size=(3,4,2)) #[height, width, colorchannel] \n",
    "print(x_og,x_og.shape)\n",
    "x_permuted=x_og.permute(2,0,1) #shifting-->[height-->2, width-->0, colorchannel-->1]\n",
    "print(x_permuted,x_permuted.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
